{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a34692-75f1-4638-a0e8-9dba8afd66db",
   "metadata": {},
   "source": [
    "# Feature Enhancement: Adding Lag Features (Recent Congestion Levels) and Weather Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56691c5e-c010-4e01-8306-e47c3ce2a321",
   "metadata": {},
   "source": [
    "This notebook combines previously engineered features (from earlier notebooks) with two important new sources of information to create the final feature set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a3725-5fd3-4292-b752-14fffd13d5f8",
   "metadata": {},
   "source": [
    "### 1. Adding Lag Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c77868-4685-44a4-be59-ded37479840d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "These features (prev_1h_severity, prev_2h_severity) are meant to help the models incorporate patterns from historical traffic severity at each location and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26520544-c6be-46d3-882f-7c7f0c500309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  road status            description           timestamp  hour weekday  \\\n",
      "0   A1   Good  No Exceptional Delays 2025-03-10 00:08:00     0  Monday   \n",
      "1   A1   Good  No Exceptional Delays 2025-03-10 00:38:00     0  Monday   \n",
      "2   A1  Minor           Minor Delays 2025-03-10 01:08:00     1  Monday   \n",
      "3   A1   Good  No Exceptional Delays 2025-03-10 01:38:00     1  Monday   \n",
      "4   A1   Good  No Exceptional Delays 2025-03-10 02:08:00     2  Monday   \n",
      "\n",
      "   day_of_week  is_weekend  is_rush_hour  severity_level  prev_1h_severity  \\\n",
      "0            0           0             0               0                -1   \n",
      "1            0           0             0               0                 0   \n",
      "2            0           0             0               1                 0   \n",
      "3            0           0             0               0                 1   \n",
      "4            0           0             0               0                 0   \n",
      "\n",
      "   prev_2h_severity  \n",
      "0                -1  \n",
      "1                -1  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 1  \n",
      "Lag features successfully created and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load existing engineered dataset \n",
    "df = pd.read_csv(\"../data/engineered_traffic_data.csv\")\n",
    "\n",
    "# Ensure timestamp is parsed correctly\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort the data by road and timestamp to calculate lags properly\n",
    "df = df.sort_values(by=['road', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "# Create lag features\n",
    "df['prev_1h_severity'] = df.groupby('road')['severity_level'].shift(1)\n",
    "df['prev_2h_severity'] = df.groupby('road')['severity_level'].shift(2)\n",
    "\n",
    "# to handle missing values for first rows (for roads where thereâ€™s not enough history)\n",
    "df['prev_1h_severity'] = df['prev_1h_severity'].fillna(-1).astype(int)\n",
    "df['prev_2h_severity'] = df['prev_2h_severity'].fillna(-1).astype(int)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "#  Save this version (before merging with weather data later on)\n",
    "df.to_csv(\"../data/engineered_traffic_with_lags.csv\", index=False)\n",
    "print(\"Lag features successfully created and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbad9be-6d75-4862-b097-4d9c268e3db1",
   "metadata": {},
   "source": [
    "### 2. Adding Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea94f571-a5ee-4964-a8b8-182861c34330",
   "metadata": {},
   "source": [
    "Gotten from https://open-meteo.com/\n",
    "\n",
    "Weather data is merged into the main dataset, providing variables such as: temperature_2m, precipitation, rain, snowfall, wind_speed_10m, wind_gusts_10m, cloud_cover.\n",
    "\n",
    "These features are meant to potentially help the models understand the environmental context of traffic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85750ba3-42fd-479b-a905-083d4fbd692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time  temperature_2m  precipitation  rain  snowfall  \\\n",
      "0 2025-03-10 00:00:00             8.7            0.0   0.0       0.0   \n",
      "1 2025-03-10 01:00:00             8.6            0.0   0.0       0.0   \n",
      "2 2025-03-10 02:00:00             8.8            0.0   0.0       0.0   \n",
      "3 2025-03-10 03:00:00             8.4            0.0   0.0       0.0   \n",
      "4 2025-03-10 04:00:00             8.0            0.0   0.0       0.0   \n",
      "\n",
      "   wind_speed_10m  wind_gusts_10m  cloud_cover  \n",
      "0             6.9            15.8           97  \n",
      "1             6.4            14.0           29  \n",
      "2             7.3            14.8           99  \n",
      "3             7.5            14.8           99  \n",
      "4             7.1            14.8           11  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weather_df = pd.read_csv(\n",
    "    '../data/open-meteo-51.49N0.16W1m.csv',\n",
    "    skiprows=3  # skip metadata, use row 4 as header\n",
    ")\n",
    "\n",
    "weather_df.columns = [col.split(' (')[0].strip() for col in weather_df.columns]\n",
    "\n",
    "weather_df['time'] = pd.to_datetime(weather_df['time'])\n",
    "\n",
    "print(weather_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af104d6-90d6-40a3-9c01-994480209d04",
   "metadata": {},
   "source": [
    "#### Weather Data Merging Approach\n",
    "\n",
    "The traffic data contains observations at 30-minute intervals, while the available weather data is recorded hourly. To integrate weather information into the traffic dataset, we aligned each traffic observation with the corresponding hourly weather conditions. This was achieved by flooring each traffic timestamp to the nearest full hour (i.e., assigning both the HH:00 and HH:30 traffic records to the same hourly weather record at HH:00).\n",
    "\n",
    "This approach assumes that weather conditions are relatively stable within each hour, allowing each hourly weather record to be used for both 30-minute traffic records in that hour. \n",
    "\n",
    "This provides a consistent, aligned dataset where every traffic observation is enriched with the most recent weather information available at that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69738d6d-e9d2-4056-99ca-07a3bb62fcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  road status            description           timestamp  hour weekday  \\\n",
      "0   A1   Good  No Exceptional Delays 2025-03-10 00:08:00     0  Monday   \n",
      "1   A1   Good  No Exceptional Delays 2025-03-10 00:38:00     0  Monday   \n",
      "2   A1  Minor           Minor Delays 2025-03-10 01:08:00     1  Monday   \n",
      "3   A1   Good  No Exceptional Delays 2025-03-10 01:38:00     1  Monday   \n",
      "4   A1   Good  No Exceptional Delays 2025-03-10 02:08:00     2  Monday   \n",
      "\n",
      "   day_of_week  is_weekend  is_rush_hour  severity_level  prev_1h_severity  \\\n",
      "0            0           0             0               0                -1   \n",
      "1            0           0             0               0                 0   \n",
      "2            0           0             0               1                 0   \n",
      "3            0           0             0               0                 1   \n",
      "4            0           0             0               0                 0   \n",
      "\n",
      "   prev_2h_severity  temperature_2m  precipitation  rain  snowfall  \\\n",
      "0                -1             8.7            0.0   0.0       0.0   \n",
      "1                -1             8.7            0.0   0.0       0.0   \n",
      "2                 0             8.6            0.0   0.0       0.0   \n",
      "3                 0             8.6            0.0   0.0       0.0   \n",
      "4                 1             8.8            0.0   0.0       0.0   \n",
      "\n",
      "   wind_speed_10m  wind_gusts_10m  cloud_cover  \n",
      "0             6.9            15.8           97  \n",
      "1             6.9            15.8           97  \n",
      "2             6.4            14.0           29  \n",
      "3             6.4            14.0           29  \n",
      "4             7.3            14.8           99  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/1q_6q8_n1fx35q947ctj0w1m0000gn/T/ipykernel_46621/2072809626.py:2: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['weather_time'] = df['timestamp'].dt.floor('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged weather data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Align traffic timestamps to full hour to match weather\n",
    "df['weather_time'] = df['timestamp'].dt.floor('H')\n",
    "\n",
    "# Merge traffic with weather\n",
    "merged_df = pd.merge(df, weather_df, left_on='weather_time', right_on='time', how='left')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df = merged_df.drop(columns=['weather_time', 'time'])\n",
    "\n",
    "print(merged_df.head())\n",
    "\n",
    "# save merged data\n",
    "merged_df.to_csv(\"../data/engineered_traffic_with_lags_and_weather.csv\", index=False)\n",
    "print(\"Successfully merged weather data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d21fc7-3eaf-44aa-abd9-9ce4e3fc4323",
   "metadata": {},
   "source": [
    "### Features scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c7958-3f26-4fab-9b51-9d31f5fa4db8",
   "metadata": {},
   "source": [
    "Scaling makes sure that features with different numeric ranges are on a comparable scale, so the model treats them fairly during learning.\n",
    "\n",
    "It transforms the feature values to a smaller, standardized range (using StandardScaler)\n",
    "\n",
    "For example:\n",
    "\n",
    "- Temperatures may range from 0Â°C to 30Â°C.\n",
    "\n",
    "- Precipitation may range from 0 mm to 10 mm.\n",
    "\n",
    "- Wind speeds may range from 0 to 40 km/h.\n",
    "\n",
    "- Cloud cover is 0-100%.\n",
    "\n",
    "These very different scales confuse many machine learning algorithms.\n",
    "\n",
    "I can scale only the weather features.\n",
    "Traffic categorical features (severity_level, lags, weekday, etc.) don't need scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b3772d7-1b44-43e4-ab4c-651599956f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['road', 'status', 'description', 'timestamp', 'hour', 'weekday', 'day_of_week', 'is_weekend', 'is_rush_hour', 'severity_level', 'prev_1h_severity', 'prev_2h_severity', 'weather_time']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02593267-9ca5-49bf-a66d-18dc5d2750c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling applied and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the full dataset\n",
    "df = pd.read_csv(\"../data/engineered_traffic_with_lags_and_weather.csv\")\n",
    "\n",
    "# Strip any possible whitespaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Select weather features\n",
    "weather_cols = ['temperature_2m', 'precipitation', 'rain', 'snowfall',\n",
    "                'wind_speed_10m', 'wind_gusts_10m', 'cloud_cover']\n",
    "\n",
    "# Apply scaling\n",
    "scaler = StandardScaler()\n",
    "df[weather_cols] = scaler.fit_transform(df[weather_cols])\n",
    "\n",
    "# Save scaled version\n",
    "df.to_csv(\"../data/engineered_traffic_with_lags_and_weather_scaled.csv\", index=False)\n",
    "\n",
    "print(\"Scaling applied and final dataset saved \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74492d-dd0f-45d0-a2c9-03091215f750",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "So now I have 2 datasets (engineered_traffic_with_lags.csv and engineered_traffic_with_lags_and_weather_scaled.csv) that I will use in the following 2 notebooks to experiment with ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d38df-7f38-4c06-bba9-d4a0520035f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
